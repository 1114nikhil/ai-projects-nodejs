## Build AI project with Node.js,OpenAI, LAngChain,Vector DB, HuggingFace, TypeScript 

## 1. OpenAI fundamentals

### 1.1. Open AI setup
-OpenAI key setup
    - https://platform.openai.com/
-Create a node Npm project
    -`npm init -y`
    -`npm install openai`
-run a prompt

### 1.2. TypeScript setup
- `npm i -D typescript ts-node @types/node`
-`npx tsc --init`

## Just put `start` startts or startjs will not work
    - "startjs": "node --env-file=.env src/index.js",
    - "start": "node -r ts-node/register --env-file=.env src/index.ts",


## to check no. of tokens in nodejs project
    -`npm i tiktoken`

## Roles
    -system
    -user
    -asistance

## OpenA api and playground parameters
    - Temperature
        higher Temperature will results in more random predections, lower Temperature will results in more Predictable predictions
        recomended range : 0.1 to 1.0
    - Top P
        higher top_p will results in more diverse pridiction,while a lower top_p will results in more focused predictions
        recomended range: 0.1 to 0.9
    - Maximum Tokens
        contorls the max no. of output tokens that model will generate in a single response
        recomended range : 16 to 2048
        max_output_tokens': integer below minimum value. Expected a value >= 16, but got 10 instead.
    - Frequnecy panality
        parameter controls the modal tendecy to repeat  token  that have already been generated,higher 
    - n
        number of choises

## 2 Simple Chat project
    - Chat with the OpenAI
    - add Chat history (context)
    - set token limit

### 2.1 Setup new chat-app project
    - `npm init -y`
    - `npm i -D typescript ts-node @types/node`
    - `npx tsc --init`
    - `npm i openai tiktoken` 

### Build chat with openAI
    - we will use console as the chat interface 
        - use `process.stdin.addListener`

### 2.3 add chat history (context)
    - you can build this by simple pushing the user and asistance in the array

### 2.4 Set the token limit
    - why keepp context small?
        - to control the cost 
        - to contorl the length of the response
        - to avoid error  due to large context of gpt-4.1-nano-2025-04-14 has limit of 1,047,576 context window

### 3 Openai Function calling and api tools
    - Why Functions calling?
        - Chatgpt only has access to the Trained data set e.g. (gpt-4.1-nano-2025-04-14 model has a knowledge cutoff date of April 2023)
        - to get the Latest data we can use Function calling
            e.g.
                what the latest price of Bitcoin or What is the date Today?

                to solve this we can call function calling.So the OpenAI can be prompted to call function calling to get the latest data
        - so we can do 
            - access the latest data or real time data 
            - modify/mutation of data ex: in a DB
            - act like a live chat bot which can interact user with the real time
    Topics to cover:
        - setup function calling
        - parameters of the function
        - multiple functions
        - project for Demo

## 3.1 Setup function calling
    - Configure the function calling
    - Decide which function to call
    - Call the function
    - call openAI with the function response

### 4 Project(Train Reservation System Asistance)
    - Recuirement:
        User should be able to ask for train between two stations
         eg.: "What are the train between Mumbai and Delhi?"
        Agent should responed with the train details
         eg.: "There are 2 trains :Rajdhani and Shatabdi."
        User should be able to ask for making reservation.
         eg.: "I want book a ticket for Rajdhani"
        Aagent should respond with the reservation details
         eg.: "Your ticket is booked for Rajdhani. Your PNR is 1234567890."

    - Tech Feature to Imaplements :
        - Function calling
            - getTrainBetweenStations(source, destination)
            - bookTicket(trainName,date)
        - Context

