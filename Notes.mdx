## Build AI project with Node.js,OpenAI, LAngChain,Vector DB, HuggingFace, TypeScript 

## 1. OpenAI fundamentals

### 1.1. Open AI setup
-OpenAI key setup
    - https://platform.openai.com/
-Create a node Npm project
    -`npm init -y`
    -`npm install openai`
-run a prompt

### 1.2. TypeScript setup
- `npm i -D typescript ts-node @types/node`
-`npx tsc --init`

## Just put `start` startts or startjs will not work
    - "startjs": "node --env-file=.env src/index.js",
    - "start": "node -r ts-node/register --env-file=.env src/index.ts",


## to check no. of tokens in nodejs project
    -`npm i tiktoken`

## Roles
    -system
    -user
    -asistance

## OpenA api and playground parameters
    - Temperature
        higher Temperature will results in more random predections, lower Temperature will results in more Predictable predictions
        recomended range : 0.1 to 1.0
    - Top P
        higher top_p will results in more diverse pridiction,while a lower top_p will results in more focused predictions
        recomended range: 0.1 to 0.9
    - Maximum Tokens
        contorls the max no. of output tokens that model will generate in a single response
        recomended range : 16 to 2048
        max_output_tokens': integer below minimum value. Expected a value >= 16, but got 10 instead.
    - Frequnecy panality
        parameter controls the modal tendecy to repeat  token  that have already been generated,higher 
    - n
        number of choises

## 2 Simple Chat project
    - Chat with the OpenAI
    - add Chat history (context)
    - set token limit

### 2.1 Setup new chat-app project
    - `npm init -y`
    - `npm i -D typescript ts-node @types/node`
    - `npx tsc --init`
    - `npm i openai tiktoken` 

### Build chat with openAI
    - we will use console as the chat interface 
        - use `process.stdin.addListener`

### 2.3 add chat history (context)
    - you can build this by simple pushing the user and asistance in the array

### 2.4 Set the token limit
    - why keepp context small?
        - to control the cost 
        - to contorl the length of the response
        - to avoid error  due to large context of gpt-4.1-nano-2025-04-14 has limit of 1,047,576 context window

### 3 Openai Function calling and api tools
    - Why Functions calling?
        - Chatgpt only has access to the Trained data set e.g. (gpt-4.1-nano-2025-04-14 model has a knowledge cutoff date of April 2023)
        - to get the Latest data we can use Function calling
            e.g.
                what the latest price of Bitcoin or What is the date Today?

                to solve this we can call function calling.So the OpenAI can be prompted to call function calling to get the latest data
        - so we can do 
            - access the latest data or real time data 
            - modify/mutation of data ex: in a DB
            - act like a live chat bot which can interact user with the real time
    Topics to cover:
        - setup function calling
        - parameters of the function
        - multiple functions
        - project for Demo

## 3.1 Setup function calling
    - Configure the function calling
    - Decide which function to call
    - Call the function
    - call openAI with the function response

### 4 Project(Train Reservation System Asistance)
    - Recuirement:
        User should be able to ask for train between two stations
         eg.: "What are the train between Mumbai and Delhi?"
        Agent should responed with the train details
         eg.: "There are 2 trains :Rajdhani and Shatabdi."
        User should be able to ask for making reservation.
         eg.: "I want book a ticket for Rajdhani"
        Aagent should respond with the reservation details
         eg.: "Your ticket is booked for Rajdhani. Your PNR is 1234567890."

    - Tech Feature to Imaplements :
        - Function calling
            - getTrainBetweenStations(source, destination)
            - bookTicket(trainName,date)
        - Context

### 5. Embedding and Similarity
    - wht are Embaddings?
    - what are open AI embeddings?
    - what are Similarity?
    - Project: Recommedation System

### 5.1 What are Embeddings?
    - Embeddings are numerical representations of data Ex.text,images,audio etc.
    - Emabedding takes the form of vector ie alist of numbers
    - Embadding latent space
        - Embeddings are used to represent the data in a latent space
        - Latent space is a high-dimensional space where similar data points are close to each other
### 5.2 What are Similarity?
    - Similarity is a measure of how similar two data points are
    - Similarity is used to find the most similar data points in the latent space
    - Similarity can be measured using various metrics like cosine similarity, Euclidean distance, etc.
    to find the similarity 
    - Dot product
        - Dot product is a measure of similarity between two vectors
        - It is calculated by multiplying the corresponding elements of the vectors and summing the results
        - Higher dot product indicates higher similarity between the vectors
    - Cosine similarity
        - Cosine similarity is a measure of similarity between two vectors based on the cosine of the angle between them
        - It is calculated by dividing the dot product of the vectors by the product
          of their magnitudes
        - Cosine similarity ranges from -1 to 1, where 1 indicates perfect similarity
        - Cosine similarity is often used in natural language processing tasks to measure the similarity between text
          documents or sentences

 
 ## Emabedding models:
    - OpenAI provides various embedding models like text-embedding-ada-002, text-embedding-babbage-001, etc.
    - These models can be used to generate embeddings for text data
    - The embeddings can be used for various tasks like similarity search, clustering, etc.

## OpenAI Emabedding
    openai.embeddings.create

## generate multiple Embadding and save it

## calculate similarity between embading